{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556f38d0",
   "metadata": {},
   "source": [
    "## KOBERT 감성분석\n",
    "- 사전(Vocabulary)\n",
    "- 크기 : 8,002\n",
    "- 한글 위키 + 뉴스 텍스트 기반으로 학습한 토크나이저(SentencePiece)\n",
    "- Less number of parameters(92M < 110M )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccea790",
   "metadata": {},
   "source": [
    "## 1. Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e419814c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "\n",
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52ae64e",
   "metadata": {},
   "source": [
    "## 2. Test Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "0de15d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 2)\n",
      "(184,) (184,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "negative    131\n",
       "positive     35\n",
       "neutral      18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('data/youtube_test_policy1.txt', sep='\\t', header=None)\n",
    "print(test_data.shape)\n",
    "test_x, test_y = test_data[0], test_data[1]\n",
    "print(test_x.shape, test_y.shape)\n",
    "\n",
    "# num label to sentiment label\n",
    "def num_to_sentiment_str(results):\n",
    "    dic = {2:'positive', 1:'neutral',0:'negative'}\n",
    "    convert_value = [dic[i] for i in results]\n",
    "    return convert_value\n",
    "\n",
    "pd.Series(num_to_sentiment_str(test_data[1])).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d558cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class 선언\n",
    "class BERTDataset(Dataset):\n",
    "    # dataset, 0, 1, tokenizer, max_len, True, False\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d0db1",
   "metadata": {},
   "source": [
    "## 3-1. 학습 전 기본 가중치 Get Model  & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "26e55166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "=== Tokenizer 예제 ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁안', '녕', '하세요', '▁', '.', '▁저', '는', '▁김', '선', '민', '▁', '입니다']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bert model\n",
    "# vocab - Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
    "bertmodel, vocab = get_pytorch_kobert_model()\n",
    "\n",
    "tokenizer = get_tokenizer() # str => /home/neuralworks/kobert/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
    "\n",
    "print('=== Tokenizer 예제 ===')\n",
    "tok('안녕하세요. 저는 김선민 입니다')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976c350",
   "metadata": {},
   "source": [
    "## 3-2. 학습 전 기본 가중치 Basic Model 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3493d562",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model parameters Setting \n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 10\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5\n",
    "\n",
    "# dataset parameters setting\n",
    "max_len = 64 # 텍스트 데이터 최대 길이\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3262d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=3, # 긍정 or 부정\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)\n",
    "    \n",
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73573173",
   "metadata": {},
   "source": [
    "## 3-3. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "b12cd4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "predict 3개 데이터 결과 [0, 0, 2] 184\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 위에서 설정한 tok, max_len, batch_size, device를 그대로 입력\n",
    "# comment : 예측하고자 하는 텍스트 데이터 리스트\n",
    "def getSentimentValue(comment, tok, max_len, batch_size, device):\n",
    "    commnetslist = [] # 텍스트 데이터를 담을 리스트\n",
    "    emo_list = [] # 감성 값을 담을 리스트\n",
    "    for c in comment: # 모든 댓글\n",
    "        commnetslist.append( [c, 5] ) # [댓글, 임의의 양의 정수값] 설정\n",
    "    \n",
    "    pdData = pd.DataFrame( commnetslist, columns = [['댓글', '감성']] )\n",
    "    pdData = pdData.values\n",
    "    test_set = BERTDataset(pdData, 0, 1, tok, max_len, True, False) \n",
    "    test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=5)\n",
    "  \n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_input):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length \n",
    "        \n",
    "        # 이때, out이 예측 결과 리스트\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        # e는 n가지 실수 값으로 구성된 리스트\n",
    "        # 0번 인덱스가 더 크면 부정, 긍정은 반대\n",
    "        for e in out:\n",
    "            value = int(torch.argmax(e).cpu())\n",
    "            emo_list.append(value)\n",
    "    return emo_list # 텍스트 데이터에 1대1 매칭되는 감성값 리스트 반환\n",
    "\n",
    "# Predict\n",
    "youtube_data_list = test_data[0].tolist()\n",
    "pred_y = getSentimentValue(youtube_data_list, tok, max_len, 8, device)\n",
    "print('predict 3개 데이터 결과', results[:3], len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe70894f",
   "metadata": {},
   "source": [
    "## 3-4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "90f5a14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.15      0.73      0.24        26\n",
      "     neutral       0.28      0.08      0.12        63\n",
      "    positive       0.60      0.22      0.32        95\n",
      "\n",
      "    accuracy                           0.24       184\n",
      "   macro avg       0.34      0.34      0.23       184\n",
      "weighted avg       0.43      0.24      0.24       184\n",
      "\n",
      "Accuracy Score :  0.24456521739130435\n"
     ]
    }
   ],
   "source": [
    "pred_y_basic = num_to_sentiment_str(pred_y)\n",
    "test_y_basic = num_to_sentiment_str(test_y)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(pred_y_basic, test_y_basic))\n",
    "print('Accuracy Score : ',accuracy_score(pred_y_basic, test_y_basic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2167c99b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## 4-1. Fine-tuning 학습 한 Modeling Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "622d0dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loading completed\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('model/kobert-policy-20.pt')\n",
    "print('model loading completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512a806",
   "metadata": {},
   "source": [
    "## 4-2. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "66337755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "The current process just got forked. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, please explicitly set TOKENIZERS_PARALLELISM=(true | false)\n",
      "predict 3개 데이터 결과 [0, 0, 2] 184\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 위에서 설정한 tok, max_len, batch_size, device를 그대로 입력\n",
    "# comment : 예측하고자 하는 텍스트 데이터 리스트\n",
    "def getSentimentValue(comment, tok, max_len, batch_size, device):\n",
    "    commnetslist = [] # 텍스트 데이터를 담을 리스트\n",
    "    emo_list = [] # 감성 값을 담을 리스트\n",
    "    for c in comment: # 모든 댓글\n",
    "        commnetslist.append( [c, 5] ) # [댓글, 임의의 양의 정수값] 설정\n",
    "    \n",
    "    pdData = pd.DataFrame( commnetslist, columns = [['댓글', '감성']] )\n",
    "    pdData = pdData.values\n",
    "    test_set = BERTDataset(pdData, 0, 1, tok, max_len, True, False) \n",
    "    test_input = torch.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=5)\n",
    "  \n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_input):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length \n",
    "        \n",
    "        # 이때, out이 예측 결과 리스트\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        # e는 n가지 실수 값으로 구성된 리스트\n",
    "        # 0번 인덱스가 더 크면 부정, 긍정은 반대\n",
    "        for e in out:\n",
    "            value = int(torch.argmax(e).cpu())\n",
    "            emo_list.append(value)\n",
    "    return emo_list # 텍스트 데이터에 1대1 매칭되는 감성값 리스트 반환\n",
    "\n",
    "# Predict\n",
    "youtube_data_list = test_data[0].tolist()\n",
    "pred_y = getSentimentValue(youtube_data_list, tok, max_len, 8, device)\n",
    "print('predict 3개 데이터 결과', results[:3], len(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaa4d6f",
   "metadata": {},
   "source": [
    "## 4.3 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1e075bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.83      0.88       149\n",
      "     neutral       0.17      0.43      0.24         7\n",
      "    positive       0.43      0.54      0.48        28\n",
      "\n",
      "    accuracy                           0.77       184\n",
      "   macro avg       0.51      0.60      0.53       184\n",
      "weighted avg       0.83      0.77      0.79       184\n",
      "\n",
      "Accuracy Score :  0.7663043478260869\n"
     ]
    }
   ],
   "source": [
    "pred_y_ft = num_to_sentiment_str(pred_y)\n",
    "test_y_ft = num_to_sentiment_str(test_y)\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print(classification_report(pred_y_ft, test_y_ft))\n",
    "print('Accuracy Score : ', accuracy_score(pred_y_ft, test_y_ft))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d81480a",
   "metadata": {},
   "source": [
    "## 5. 최종 정리\n",
    "\n",
    "- 실험 결과\n",
    "    - 현재 모델의 성능 측정을 위해 데이터셋을 7대 3으로 나누어 테스트 한 결과\n",
    "    - Fine-tuning 시 기존 학습전보다 성능이 향상함을 보임.\n",
    "    - Generalized 학습 된 네이버와, Fine-tuning 한 KoBERT가 어느정도 비슷한 성능을 보임.\n",
    "    - 단 여기서 KoBERT는 아래와 같은 문제가 아직 남아있어 개선 가능의 여지가 많음.\n",
    "\n",
    "- 추가 개선 가능 사항 및 필요 사항.\n",
    "    - 데이터의 수가 비교적 적음 (일반적으로 자연어 Task가 일반화 되기 위해선 많은 데이터 학습이 필요) \n",
    "    - 긍정, 부정, 중립간의 라벨이 불균형해 비율이 낮은 라벨은 잘 분류를 못할 수 있음 => Balanced 한 데이터 수집 필요\n",
    "    \n",
    "- 추가\n",
    "    - 한 도메인에(정치 or 식품) 여러 기사 댓글 등 정답이 분류된 라벨별 300개 이상 데이터로 실험 필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cfea22c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(184, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>naver_결과</th>\n",
       "      <th>azure_결과</th>\n",
       "      <th>결과</th>\n",
       "      <th>naver 비교</th>\n",
       "      <th>azure  비교</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>경기도에 사는것들이 없나보구나</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>민주당 대선후보들 이재명지사님빼고 다 이상함  다른시.도 민들이 보편지급하는걸 좋아...</td>\n",
       "      <td>negative</td>\n",
       "      <td>mixed</td>\n",
       "      <td>positive</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>저게 맞지</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>경기도 잘한다. ㅈㄹ 말고 반성해라</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>지자체 공산당이네..</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>댓글들이  이재명지지자들이  많네요</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>재명아, 니 돈으로 주나   이런자는 대통 되서는 안됩니다  공짜 아닙니다  골병듭...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>이재명은  마음대로  할수 있는 경기도지사 절대  사표 내지  마라</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>대통령 출마한사람이 할래면 다하지 쪽팔리다 경기도민은 야찍어 나머지는 윤 찍자  무흣</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>이재명이는 도지사 계급장 떼고 떠들어라  다른 사람들이 시장, 도지사, 총리, 장관...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    댓글  naver_결과  azure_결과  \\\n",
       "428                                   경기도에 사는것들이 없나보구나  negative   neutral   \n",
       "429  민주당 대선후보들 이재명지사님빼고 다 이상함  다른시.도 민들이 보편지급하는걸 좋아...  negative     mixed   \n",
       "430                                              저게 맞지   neutral  positive   \n",
       "431                                경기도 잘한다. ㅈㄹ 말고 반성해라  negative  positive   \n",
       "432                                        지자체 공산당이네..  negative   neutral   \n",
       "..                                                 ...       ...       ...   \n",
       "607                                댓글들이  이재명지지자들이  많네요   neutral   neutral   \n",
       "608  재명아, 니 돈으로 주나   이런자는 대통 되서는 안됩니다  공짜 아닙니다  골병듭...  negative  negative   \n",
       "609              이재명은  마음대로  할수 있는 경기도지사 절대  사표 내지  마라  negative  negative   \n",
       "610    대통령 출마한사람이 할래면 다하지 쪽팔리다 경기도민은 야찍어 나머지는 윤 찍자  무흣  negative   neutral   \n",
       "611  이재명이는 도지사 계급장 떼고 떠들어라  다른 사람들이 시장, 도지사, 총리, 장관...  negative  positive   \n",
       "\n",
       "           결과 naver 비교 azure  비교  \n",
       "428  negative        T         F  \n",
       "429  positive        F         F  \n",
       "430  positive        F         T  \n",
       "431  negative        T         F  \n",
       "432  negative        T         F  \n",
       "..        ...      ...       ...  \n",
       "607  positive        F         F  \n",
       "608  negative        T         T  \n",
       "609  negative        T         T  \n",
       "610  negative        T         F  \n",
       "611  negative        T         F  \n",
       "\n",
       "[184 rows x 6 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_data = pd.read_excel('data/Youtube댓글정리_httpsyoutu.belm7p--F7eF0_이재명_모든경기도민에_재난지원금_정리완료.xlsx')\n",
    "youtube_data = youtube_data.iloc[:-4]\n",
    "youtube_data = youtube_data[['댓글','naver_결과', 'azure_결과', '결과', 'naver 비교', 'azure  비교']] # kobert_결과, 'kobert 비교'\n",
    "\n",
    "size = int(len(youtube_data)*0.7)\n",
    "youtube_data = youtube_data.iloc[size:]\n",
    "print(youtube_data.shape)\n",
    "youtube_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ef63eac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>댓글</th>\n",
       "      <th>naver_결과</th>\n",
       "      <th>azure_결과</th>\n",
       "      <th>결과</th>\n",
       "      <th>naver 비교</th>\n",
       "      <th>azure  비교</th>\n",
       "      <th>kobert_학습전 결과</th>\n",
       "      <th>kobert 학습전 비교</th>\n",
       "      <th>kobert_학습후 결과</th>\n",
       "      <th>kobert 학습후 비교</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>경기도에 사는것들이 없나보구나</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>neutral</td>\n",
       "      <td>F</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>민주당 대선후보들 이재명지사님빼고 다 이상함  다른시.도 민들이 보편지급하는걸 좋아...</td>\n",
       "      <td>negative</td>\n",
       "      <td>mixed</td>\n",
       "      <td>positive</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>positive</td>\n",
       "      <td>T</td>\n",
       "      <td>negative</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>저게 맞지</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>negative</td>\n",
       "      <td>F</td>\n",
       "      <td>positive</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>경기도 잘한다. ㅈㄹ 말고 반성해라</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>neutral</td>\n",
       "      <td>F</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>지자체 공산당이네..</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>neutral</td>\n",
       "      <td>F</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>댓글들이  이재명지지자들이  많네요</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>negative</td>\n",
       "      <td>F</td>\n",
       "      <td>negative</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>재명아, 니 돈으로 주나   이런자는 대통 되서는 안됩니다  공짜 아닙니다  골병듭...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>positive</td>\n",
       "      <td>F</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>이재명은  마음대로  할수 있는 경기도지사 절대  사표 내지  마라</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>neutral</td>\n",
       "      <td>F</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>대통령 출마한사람이 할래면 다하지 쪽팔리다 경기도민은 야찍어 나머지는 윤 찍자  무흣</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>positive</td>\n",
       "      <td>F</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>이재명이는 도지사 계급장 떼고 떠들어라  다른 사람들이 시장, 도지사, 총리, 장관...</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>neutral</td>\n",
       "      <td>F</td>\n",
       "      <td>negative</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    댓글  naver_결과  azure_결과  \\\n",
       "428                                   경기도에 사는것들이 없나보구나  negative   neutral   \n",
       "429  민주당 대선후보들 이재명지사님빼고 다 이상함  다른시.도 민들이 보편지급하는걸 좋아...  negative     mixed   \n",
       "430                                              저게 맞지   neutral  positive   \n",
       "431                                경기도 잘한다. ㅈㄹ 말고 반성해라  negative  positive   \n",
       "432                                        지자체 공산당이네..  negative   neutral   \n",
       "..                                                 ...       ...       ...   \n",
       "607                                댓글들이  이재명지지자들이  많네요   neutral   neutral   \n",
       "608  재명아, 니 돈으로 주나   이런자는 대통 되서는 안됩니다  공짜 아닙니다  골병듭...  negative  negative   \n",
       "609              이재명은  마음대로  할수 있는 경기도지사 절대  사표 내지  마라  negative  negative   \n",
       "610    대통령 출마한사람이 할래면 다하지 쪽팔리다 경기도민은 야찍어 나머지는 윤 찍자  무흣  negative   neutral   \n",
       "611  이재명이는 도지사 계급장 떼고 떠들어라  다른 사람들이 시장, 도지사, 총리, 장관...  negative  positive   \n",
       "\n",
       "           결과 naver 비교 azure  비교 kobert_학습전 결과 kobert 학습전 비교 kobert_학습후 결과  \\\n",
       "428  negative        T         F       neutral             F      negative   \n",
       "429  positive        F         F      positive             T      negative   \n",
       "430  positive        F         T      negative             F      positive   \n",
       "431  negative        T         F       neutral             F      negative   \n",
       "432  negative        T         F       neutral             F      negative   \n",
       "..        ...      ...       ...           ...           ...           ...   \n",
       "607  positive        F         F      negative             F      negative   \n",
       "608  negative        T         T      positive             F      negative   \n",
       "609  negative        T         T       neutral             F      negative   \n",
       "610  negative        T         F      positive             F      negative   \n",
       "611  negative        T         F       neutral             F      negative   \n",
       "\n",
       "    kobert 학습후 비교  \n",
       "428             T  \n",
       "429             F  \n",
       "430             T  \n",
       "431             T  \n",
       "432             T  \n",
       "..            ...  \n",
       "607             F  \n",
       "608             T  \n",
       "609             T  \n",
       "610             T  \n",
       "611             T  \n",
       "\n",
       "[184 rows x 10 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 전 \n",
    "youtube_data['kobert_학습전 결과'] = pred_y_basic\n",
    "youtube_data['kobert 학습전 비교'] = youtube_data['kobert_학습전 결과'] == youtube_data['결과']\n",
    "youtube_data['kobert 학습전 비교'] = youtube_data['kobert 학습전 비교'].apply(lambda x : 'T' if x==True else 'F')\n",
    "\n",
    "# 학습 후\n",
    "youtube_data['kobert_학습후 결과'] = pred_y_ft\n",
    "youtube_data['kobert 학습후 비교'] = youtube_data['kobert_학습후 결과'] == youtube_data['결과']\n",
    "youtube_data['kobert 학습후 비교'] = youtube_data['kobert 학습후 비교'].apply(lambda x : 'T' if x==True else 'F')\n",
    "youtube_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f29541",
   "metadata": {},
   "source": [
    "## 6. 최종 정리 Score 및 csv 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a9c55945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure API Score: 50.54 \n",
      "Naver API Score: 77.17 \n",
      "Kobert 학습전 Score: 24.46 \n",
      "Kobert 학습후 Score: 76.63\n"
     ]
    }
   ],
   "source": [
    "az_score = np.round(100*len(youtube_data[youtube_data['azure  비교']=='T']) / len(youtube_data),2)\n",
    "nv_score = np.round(100*len(youtube_data[youtube_data['naver 비교']=='T']) / len(youtube_data),2)\n",
    "kb_score1 = np.round(100*len(youtube_data[youtube_data['kobert 학습전 비교']=='T']) / len(youtube_data),2)\n",
    "kb_score2 = np.round(100*len(youtube_data[youtube_data['kobert 학습후 비교']=='T']) / len(youtube_data),2)\n",
    "print('Azure API Score:', az_score, '\\nNaver API Score:', nv_score, '\\nKobert 학습전 Score:', kb_score1, '\\nKobert 학습후 Score:', kb_score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f84c971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_data.to_csv('youtube_정치_이재명..모델_학습_전후_결과_비교.csv', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
