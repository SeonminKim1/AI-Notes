{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SqueezeNet\n",
    "\n",
    "![squeezenet](img/squeezenet.png)\n",
    "- 1x1 conv로 Pointwise conv 수행 (channel reduction)\n",
    "- 파라미터 조정을 통한 최적 구조를 찾아내려고도 함 (3x3 필터 갯수 등) \n",
    "- SqueezeNet은 AlexNet과 비슷한 정확도를 가지지만 weight는 1/50배 수준으로 상당히 가벼움\n",
    "- 기존의 사용하였던 3 x 3 필터를 일부를 1 x 1 필터로 대체 -> 1 x 1 필터를 사용함으로써 weight의 수를 1/9로 감소\n",
    "- input 채널의 수를 3 x 3 필터를 이용하여 줄임.\n",
    "-  downsample을 늦게 적용하여 convolution layer가 큰 activation map을 가질 수 있도록 함\n",
    "- 데이터 downsample을 늦게 할수록 (예를 들어 stride를 1보다 크게 하여서 downsample 하는 작업을 늦게 적용함) 더 많은 정보들이 layer에 포함될 수 있음.\n",
    "- 이 방법을 통하여 모델은 가능한 작게 만들지만, 정확도는 최대한 크게 만들 수 있음\n",
    "\n",
    "### Fire module\n",
    "- fire module은 2개의 layer(Squeeze layer와 Expansion layer)로 이루어져 있음\n",
    "- Squeeze layer가 먼저 나온 뒤 Expansion layer가 따라서 나옵니다.\n",
    "\n",
    "### Squeeze Layer\n",
    "- Squeeze layer는 1x1 convolution으로 이루어져 있습니다.\n",
    "- 1x1 convolution은 input 데이터의 모든 channel을 하나로 합친 뒤 input channel의 수를 줄여서 다음 layer에 전달하는 역할을 합니다.\n",
    "간단하게 말하면 channel 수를 조절하는 역할을 합니다.\n",
    "\n",
    "### Expansion layer\n",
    "- 1 x 1 convolution이 3 x 3 convolution과 섞인 형태\n",
    "- 1 x 1 convolution은 spatial structure를 감지하기 어렵지만 이전 layer의 channel들을 다양한 방법으로 결합함\n",
    "- 3 x 3 convolution은 이미지 내의 structure를 잘 잡아냄\n",
    "- 1 x 1 과 3 x 3 필터 사이즈의 convolution을 섞어서 사용함으로써 표현력이 증가하고 파라미터의 숫자도 동시에 줄일 수 있습니다.\n",
    "- 이 때 주의할 점은 1 x 1 convolution과 3 x 3 convolution 결과의 크기를 같게 하려면 적당한 padding 사용 필요. (사이즈가 같아야 적층 가능)\n",
    "- padding을 이용해 두 kernel의 결과를 같게 하여 적층\n",
    "\n",
    "### Squeezenet Architecture\n",
    "- SqueezeNet은 8개의 fire module을 사용\n",
    "- input/output 각각에 1개의 convolution layer를 사용\n",
    "- SqueezeNet에서 Fully Connected Layer는 전혀 사용되지 않았음\n",
    "- Fully connected layer는 상당히 많은 양의 parameter를 가지고 있고, convolution layer에 비교하면 상당히 많음\n",
    "\n",
    "- **너무 많은 양의 parameter에 맞추다 보면 overfitting이 발생할 확률도 커지며, SqueezeNet에서는 Global Average Pooling을 사용합니다.**\n",
    "- Pooling layer은 weight 값이 없기 때문에 model 사이즈를 더 크게 만들지 않음\n",
    "- parameter를 더 만들어 내지 않기 때문에 Fully connected layer에 비해서 overfitting 문제에 좀 더 자유로움\n",
    "\n",
    "#### Global Average Pooling\n",
    "- **Global average pooling은 이전의 convolution layer로 부터 각각의 channel을 전달 받은 다음 모든 값에 대하여 average를 취해줌**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "- https://gaussian37.github.io/dl-concept-mobilenet-and-squeeznet/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
