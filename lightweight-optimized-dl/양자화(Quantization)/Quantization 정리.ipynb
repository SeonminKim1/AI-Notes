{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantization 정리\n",
    "- 신경망 모델 양자화 분류\n",
    "    - Post-training Quantization\n",
    "        - floating point 모델로 training\n",
    "        - weight 결과에 대한 양자화 진행\n",
    "        \n",
    "        - 장점\n",
    "            - 파라미터 size가 큰 대형모델에 대해 정확도 하락 폭이 작다\n",
    "            - 파라미터 size가 작은 소형 모델에서는 적합하지 않음\n",
    "        - 예시\n",
    "            - Hardware Limitation이 있는 경우는 Post training Quantization이 필요\n",
    "            - TFLite\n",
    "    - Quantization-aware-training (Fake Quantization)\n",
    "        - Weights / biases 는 기본적으로는 floating point 형태로 저장되어 있음. \n",
    "        - Matrix multiplication(가중치 x input) --> Bias addition --> Scale down to the final scale (8-bit) --> cast down to uint8(양수화) --> apply the activation function\n",
    "        - inference 시에만 quantized 되어 트레이닝 됨. \n",
    "        - Weights의 quantization parameter의 경우, 지속적으로 min / max 값에 따라 조정되고, activation은 그럴 수 없으므로 (현재 값이 진짜 최대 / 최소인지 알 수 없다!) Exponential moving averages 방법으로 조정된다. (Equation 12)\n",
    "\n",
    "\n",
    "- **Post-training vs Aware training 차이**\n",
    "    - post 처럼 float으로 학습한담에 양자화 때려버리면 그거는 정말 모델을 목적으로 한 결과보다는 그냥 양자화 작업인거고,\n",
    "    - aware는 bias랑 weight랑 양자화 결과를 보면서 loss를 줄인거니까 이게 더 양자화모델을 목적으로 한 것이라고 할 수 있다의 느낌\n",
    "        \n",
    "![post_vs_aware](img/post_vs_aware.png)\n",
    "\n",
    "## 참고문헌\n",
    "- https://blog.est.ai/2020/03/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EB%AA%A8%EB%8D%B8-%EC%95%95%EC%B6%95-%EB%B0%A9%EB%B2%95%EB%A1%A0%EA%B3%BC-bert-%EC%95%95%EC%B6%95/ // 딥러닝 모델 압축 방법론과 BERT 압축\n",
    "\n",
    "- https://jeongukjae.github.io/posts/q8bert/ // Q8Bert:Quantization 리뷰\n",
    "- https://wannabeaprogrammer.tistory.com/42 // Quantization-aware training\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
