{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Visualize Neural Networks (XAI)\n",
    "- 딥러닝 모델에서 **이미지를 설명하기위한 방법**으로는 크게 세가지 방법\n",
    "    - 1) **Pertubation Based Methods (PBMs)**\n",
    "        - 입력값에 대한 작은 변화(purtubation)를 주어 예측값 변화에 따른 중요도 파악 방법\n",
    "        - ex) LIME\n",
    "    - 2) Backpropagation Based Method (BBMs)\n",
    "        - 입력값에 대한 backpropagation을 통한 오차의 정도를 계산하여 각 픽셀의 중요도를 나타내는 방법\n",
    "        - ex) LRP(Layer-wise Relevance Propagation), DeepLIFT, SmoothGrad, VarGrad\n",
    "    - 3) Activation Based Methods (ABMs)\n",
    "        - 이미지 위에 영향이 있는 부분에 대해서 heat-map을 overlap하여 보기 쉽게 표현 가능한 방법\n",
    "        - ex) CAM(Class Activation Map), Grad-CAM(Gradient-CAM), Grad-CAM++\n",
    "        \n",
    "## 참고문헌\n",
    "- https://datanetworkanalysis.github.io/2019/09/10/HowtoExplainAI\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 대리 분석(Surrogate Analysis) 개론\n",
    "- 본래 인공지능 모델이 너무 복잡하여 분석이 불가능 할 때 **유사한 기능을 흉내 내는 모델(설명 가능한 모델)을 대리로 만들어 본래 모델을 분석하는 기법**\n",
    "- 근사치 모델(Approximation model), 반응 표면 기법(Response Surface Model, RSM), 에뮬레이터(Emluator) 등의 이름으로 불림\n",
    "    - ex) 모델 A (SVM) 을 모델 B (Tree, Linear Regression 등)로 설명\n",
    "- **설명 가능한 모델 B가 모델 A와 결과가 어느정도 비슷하다면, 원래 모델 A가 어떻게 학습됬을지 해석 가능 하다.**\n",
    "\n",
    "- 대리 분석 종류\n",
    "    - 5.1) 글로벌 대리 분석 (Global Surrogate)\n",
    "        - 학습 데이터 (일부 or 전체)를 사용해서 대리 분석 모델 구축하는 방법\n",
    "    - 5.2) 로컬 대리 분석 (Local Surrogate Analysis)\n",
    "        - 모델을 이용해 학습 데이터 하나를 해석학습 데이터 하나를 해석\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-1. 글로벌 대리 분석 (Global Surrogate)\n",
    "\n",
    "### 수행 방법\n",
    "- 1) 데이터 집합 X선택 (학습 데이터 일부 or 전체)\n",
    "- 2) 데이터(X) 학습 및 블랙박스 모델 A 생성\n",
    "- 3) XAI 대리 분석 모델 선택 (B), 단 B는 설명 가능해야 함\n",
    "- 4) 데이터(X) 학습 및 모델 B 생성\n",
    "- 5) 데이터(X)에 대한 A와 B가 예측 결과가 유사하도록 튜닝\n",
    "    - A와 B가 얼마나 유사한가 (= B가 A에 얼마나 근사됬나) 는 SSE(Sum Squared Error), SST등으로 측정 \n",
    "    - $R^2 = 1 - SSE/SST$\n",
    "    - R square 결정지수가 1에 가까워지면 모델 설명에 합리적\n",
    "    - R square 결정지수가 0에 가까워지면 모델 설명에 비합리적\n",
    "\n",
    "- 6) B 모델을 통한 A모델 설명\n",
    "    \n",
    "### 장점 및 주의사항\n",
    "- 글로벌 대리 분석법은 유연하다 -> A 블랙박스를 설명하기 위해 설명가능한 B,C,D 선택 가능\n",
    "- 모델 A에 대한 직접설명이 아닌 간접설명이므로, B 모델을 이용한 설명에 대한 결함\n",
    "- **전통적인 머신러닝 기법에 적용하기 좋다**\n",
    "    - 신경망 딥러닝은 블랙박스 적인 측면이 강하니까 A거나 B더라도 합리성이 약함\n",
    "- '모델 B가 A를 얼마나 모방해야 해석을 했을 때 유의하다고 판단 할 수 있을까'에 대한 문제에서 주관적이다.\n",
    "    - 어떤 모델은 80%만 설명해도 합리적, 타 모델은 99%일떄 합리적\n",
    "    - 측정함수와 어떤 모델로 설명하고자 했냐에 따라 XAI 에 대한 설명이 주관적\n",
    "- 데이터 집합 X에 대한 편향성\n",
    "    - 학습데이터가 일반적인지도 고민    \n",
    "    \n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2. 로컬 대리 분석 (Local Surrogate)\n",
    "- **데이터 하나에 대해 모델이 해석하는 과정을 분석하는 기법**\n",
    "- 글로벌 대리 분석이 모델 A를 설명하기 위해 모델 B를 가지고 설명했다면,\n",
    "    - 모델의 가중치에 신경써서 모델을 해석하는 방법\n",
    "- 로컬 대리 분석은 모델 A의 개별 예측에 대한 결과 설명을 위한 것 \n",
    "\n",
    "### LIME (Local Interpretable Model-agnostic Explanations)\n",
    "- Paper : [Why Should I Trust You?\": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)\n",
    "- LIME 은 PBM (Perturbation Based Methods) 방법의 일종\n",
    "    - 입력값에 대한 변화를 주어 예측값이 달라지게 하여 비교하는 방법\n",
    "    - Input 데이터를 LIME 알고리즘에 맞게 변화를 주고, Black-Box Model에 넣어 Return된 결과를 가지고 해석 \n",
    "- **논문의 가장 큰 전제 : 데이터 공간의 전체에서 모형을 설명하는 것은 어려울지라도, 국소적인 데이터 공간(설명하고자 하는 데이터와 가까운 거리에 있는 공간)에서는 의미 있는 모형으로 설명해낼 수 있다는 것 !**\n",
    "\n",
    "![lime_prerequisite](img/lime_prerequisite.PNG)\n",
    "- 우측의 빨간색 3점과 좌측의 파란색 2점은 설명이 힘들지만, Local 주변에 있는 데이터는 충분히 설명 가능하다. \n",
    "- 보고자 하는 데이터 부분에 모델을 근사하여 보겠다는 것.\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Lime Algorithm\n",
    "\n",
    "![lime_math](img/lime_math.png)\n",
    "- $x$ : 이미지내 특정 관심 영역\n",
    "- $π_x$ (슈퍼 픽셀(Super pixel) : 초점 x로 부터 관심있는 영역을 키워나갈시 **x와 동일한 정보를 가지고 있다고 간주할 수 있는 영역** \n",
    "- $m_x$ : $π_x$ 영역에 대한 마스킹 정보\n",
    "- $G$ : 잠재적으로 해석이 가능한 모형의 집합 (Linear model, decision trees)\n",
    "- $f$ (블랙박스 모델)\n",
    "    - 이미지 전체를 입력으로 받아 **목표 조건(ex. 38번째 특정 사람이다) 을 수행하는 블랙 박스 모델**\n",
    "- $g$ (사람이 이해하는 모델)\n",
    "    - 슈퍼 픽셀 $π_x$의 마스킹 정보 $m_x$를 입력받아 $f(π_x)$d와 동일한 결과가 나오게 수행하는 회귀 모델 \n",
    "    - **단순 선형결합 모델로 표현 $g(m1, m2, ...) = w_1*m_1 + w_2 * m_2 ...$**\n",
    "- $Ω(g)$ (모형의 복잡도)\n",
    "    - Ω(g)는 Dicision Tree, Linear model에서 각각 나무의 깊이, non zero 계수의 갯수를 의미\n",
    "\n",
    "- 최종\n",
    "    - 즉 **슈퍼 픽셀 $π_x$에 대해 분류 모델 $f$의 예측 결과** 와 \n",
    "    - **마스킹 데이터 $m_x$에 대한 회귀 모델 $g$의 검증 결과** 비교, 유사성을 계산\n",
    "    \n",
    "    - $argmin L(f.g.π_x)$ : Loss함수 값이 최저가 되게 하는 슈퍼 픽셀 조합을 찾음\n",
    "    - 아래 그림 기준 유사성(proximity)이 가장 높은 ($π2, π4$) 조합 선택\n",
    "    \n",
    "![lime1](img/lime1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Lime Training Step\n",
    "- 1) 예측결과를 설명하기 원하는 Input X를 설정 (노란점)\n",
    "- 2) normal distribution을 이용한 Sample Data 생성\n",
    "- 3) **모델 해석을 위해 가까운 Sample 들의 높은 weight 매김** \n",
    "    - Exponential smoothing, 가까운 점에는 높은 가중치 주는 방식 주는 방식\n",
    "- 4) **주변 weighted sample을 학습, locally learned model(decision tree, linear model 등등)을 만들어 interpretable model로 구성**\n",
    "- 5) local model을 해석하기 위한 결과 설명\n",
    "\n",
    "![line_tabular](img/line_tabular.png)\n",
    "\n",
    "<hr>\n",
    "\n",
    "## LIME의 장점\n",
    "- 장점\n",
    "    - 모델 Agnostic : LIME 적용은 모델의 종류에 구애받지 않는다. \n",
    "        - 해당 Local 데이터에 대한 설명가능한 적합한 모델을 가지고 설명\n",
    "- 단점 \n",
    "    - LIME의 불확실성\n",
    "        - 슈퍼 픽셀을 구하는 알고리즘, 모델 g의 결정 경계를 확정 짓는 방식이 Non-deterministic 임. (출력 결과가 항상 일정하지 않고 달라질수 있다는 것)\n",
    "    - 데이터의 일부 사용으로 인한 일관성 보전이 어려운 약점\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "- https://yjjo.tistory.com/3\n",
    "- https://dodonam.tistory.com/202\n",
    "- https://analysisbugs.tistory.com/218\n",
    "- https://blogs.sas.com/content/saskorea/2018/12/10/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%ED%95%B4%EC%84%9D%EB%A0%A5-%EC%8B%9C%EB%A6%AC%EC%A6%88-4%ED%83%84-%EB%9D%BC%EC%9E%84lime%EC%9C%BC%EB%A1%9C-%EB%AA%A8%EB%8D%B8-%ED%95%B4%EC%84%9D%EB%A0%A5/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
