{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch API & Library\n",
    "- https://pytorch.org/vision/stable/\n",
    "\n",
    "![pytorch_api_library](img/pytorch_api_library.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchVision Package Reference\n",
    "\n",
    "### 1) Torchvision.datasets \n",
    "- Face\n",
    "    - CelebA (얼굴데이터셋)\n",
    "    \n",
    "\n",
    "- Image Classification\n",
    "    - CIFAR (사물 데이터셋)\n",
    "    - ImageNet\n",
    "    - MNIST\n",
    "        - EMNIST(알파벳 + 숫자)\n",
    "        - Fashion-MNIST\n",
    "        - KMNIST(고대 중세 일본문자)\n",
    "        - QMNIST\n",
    "    - LSUN (Scene classification)\n",
    "    \n",
    "\n",
    "- Segmentation\n",
    "    - Cityscapes(도시 길거리 데이터셋, segmentation용),\n",
    "    \n",
    "\n",
    "- Object Detection\n",
    "    - COCO, VOC (Captioning and Detection)\n",
    "    \n",
    "\n",
    "- Image Description\n",
    "    - Flickr\n",
    "    \n",
    "\n",
    "- Etc\n",
    "    - FakeData(Random Noise Data)\n",
    "    - HMDB51 (action classification dataset)\n",
    "    - Kinetics-400 / Omniglot / PhotoTour / Places365\n",
    "    - SBD / SBU / STL10 / SVHN / UCF101 / USPS\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Torchvision.io\n",
    "- performing IO operations, reading and writing video and images.\n",
    "\n",
    "- Video (Function 기반)\n",
    "    - read_video, read_video_timestamps, write_video\n",
    "\n",
    "\n",
    "- Fine-grained video API (Class 기반)\n",
    "    - Class : VideoReader\n",
    "\n",
    "\n",
    "- Image\n",
    "    - read_image, decode_image, encode_jpeg, write_jpeg, encode_png, write_png ...\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Torchvision.models\n",
    "- import torchvision.models as models\n",
    "    - ex) mobilenet_v3_large = models.mobilenet_v3_large()\n",
    "    - ex) inception = models.inception_v3()\n",
    "    \n",
    "    \n",
    "#### Classification\n",
    "- AlexNet, VGG, ResNet, SqueezeNet, DenseNet\n",
    "- Inception v3, GoogLeNet, ShuffleNet v2\n",
    "- MobileNetV2, MobileNetV3, \n",
    "- ResNeXt, Wide ResNet\n",
    "- MNASNet\n",
    "\n",
    "\n",
    "#### Quantized Models\n",
    "- INT8 quantized models\n",
    "- ex) resnet50 = models.quantization.resnet50()\n",
    "- ex) shufflenet_v2_x1_5 = models.quantization.shufflenet_v2_x1_5()\n",
    "\n",
    "\n",
    "#### Semantic Segmentation\n",
    "- FCN ResNet50, ResNet101\n",
    "- DeepLabV3 ResNet50, ResNet101, MobileNetV3-Large\n",
    "- LR-ASPP MobileNetV3-Large\n",
    "\n",
    "\n",
    "#### Object Detection\n",
    "- Faster R-CNN ResNet-50 FPN, Faster R-CNN MobileNetV3-Large FPN, Faster R-CNN MobileNetV3-Large 320 FPN\n",
    "- RetinaNet ResNet-50 FPN, Mask R-CNN ResNet-50 FPN\n",
    "\n",
    "\n",
    "#### Keypoint R-CNN\n",
    "- Keypoint R-CNN ResNet-50 FPN\n",
    "\n",
    "\n",
    "#### Video classification\n",
    "- ResNet 3D 18, ResNet MC 18, ResNet (2+1)D\n",
    "\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Torchvision.ops\n",
    "- implements operators that are specific for Computer Vision.\n",
    "\n",
    "- API Method (torchvision.ops.)\n",
    "    - nms, batched_nms\n",
    "    - remove_small_boxes, clip_boxes_to_image\n",
    "    - box_convert : xyxy to xywh, cxcywh\n",
    "    - box_area, box_iou, roi_align, ps_roi_align\n",
    "    - roi_pool, ps_roi_pool\n",
    "    - sigmoid_focal_loss\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Torchvision.transforms\n",
    "- class : torchvision.transforms.Compose(transforms)\n",
    "- transforms (class 들)\n",
    "    - CenterCrop(), RandomCrop()\n",
    "    - ToTensor()\n",
    "    - Normalize(), Resize(), Scale(), Pad() (padding)\n",
    "    - RandomHorizontalFlip(), RandomVerticalFlip(), RandomPerspective()\n",
    "    - RandomAffine(), RandomRotation(), \n",
    "    - ColorJitter(), RandomErasing(), GaussianBlur()\n",
    "    \n",
    "- 최종 example\n",
    "    - 1) transforms.Compose([transforms.CenterCrop(10), transforms.ToTensor()])\n",
    "    - 2) transforms = torch.nn.Sequential(transforms.CenterCrop(10), transforms.Normalize(0.485, 0.456, 0.406))\n",
    "    \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6) torchvision.utils\n",
    "- torchvision.utils.make_grid : Make a grid of images.\n",
    "- torchvision.utils.save_image : Save a given Tensor into an image file\n",
    "- torchvision.utils.draw_bounding_boxes : Draws bbox on given image\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
