{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confused-disorder",
   "metadata": {},
   "source": [
    "## Image Datasets\n",
    "- https://www.kaggle.com/airplane2230/apparel-image-dataset-2 // Apparel image dataset 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Library Import 및 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seventh-costume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>black</th>\n",
       "      <th>blue</th>\n",
       "      <th>brown</th>\n",
       "      <th>green</th>\n",
       "      <th>red</th>\n",
       "      <th>white</th>\n",
       "      <th>dress</th>\n",
       "      <th>shirt</th>\n",
       "      <th>pants</th>\n",
       "      <th>shorts</th>\n",
       "      <th>shoes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./clothes_dataset\\blue_shorts\\256d854b55ac32ea...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./clothes_dataset\\red_pants\\584f778aece14f07c2...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./clothes_dataset\\green_pants\\ec543ca241cefb2b...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./clothes_dataset\\brown_shorts\\c8db9e0f7010592...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./clothes_dataset\\white_dress\\551373c80717c5b0...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  black  blue  brown  \\\n",
       "0  ./clothes_dataset\\blue_shorts\\256d854b55ac32ea...    0.0   1.0    0.0   \n",
       "1  ./clothes_dataset\\red_pants\\584f778aece14f07c2...    0.0   0.0    0.0   \n",
       "2  ./clothes_dataset\\green_pants\\ec543ca241cefb2b...    0.0   0.0    0.0   \n",
       "3  ./clothes_dataset\\brown_shorts\\c8db9e0f7010592...    0.0   0.0    1.0   \n",
       "4  ./clothes_dataset\\white_dress\\551373c80717c5b0...    0.0   0.0    0.0   \n",
       "\n",
       "   green  red  white  dress  shirt  pants  shorts  shoes  \n",
       "0    0.0  0.0    0.0    0.0    0.0    0.0     1.0    0.0  \n",
       "1    0.0  1.0    0.0    0.0    0.0    1.0     0.0    0.0  \n",
       "2    1.0  0.0    0.0    0.0    0.0    1.0     0.0    0.0  \n",
       "3    0.0  0.0    0.0    0.0    0.0    0.0     1.0    0.0  \n",
       "4    0.0  0.0    1.0    1.0    0.0    0.0     0.0    0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "DATA_PATH = 'data/multi_label/'\n",
    "train_df = pd.read_csv(DATA_PATH + 'train.csv', index_col=0)\n",
    "val_df = pd.read_csv(DATA_PATH + 'val.csv', index_col=0)\n",
    "test_df = pd.read_csv(DATA_PATH + 'test.csv', index_col=0)\n",
    "\n",
    "# class column들\n",
    "class_col = list(train_df.columns[1:])\n",
    "print(class_col)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-moral",
   "metadata": {},
   "source": [
    "## 2-1. Image Data Generator 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alternative-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 제너레이터를 정의합니다.\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "def get_steps(num_samples, batch_size):\n",
    "    if (num_samples % batch_size) > 0:\n",
    "        return (num_samples // batch_size) + 1\n",
    "    else:\n",
    "        return num_samples // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-baltimore",
   "metadata": {},
   "source": [
    "## 2-2. Generator - flow from dataframe 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Generator\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory = DATA_PATH, # os.getcwd() 기반 ~\n",
    "    x_col = 'image',\n",
    "    y_col = class_col,\n",
    "    target_size = (112, 112),\n",
    "    color_mode='rgb',\n",
    "    class_mode='other',\n",
    "    batch_size=batch_size,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    directory = DATA_PATH,\n",
    "    x_col = 'image',\n",
    "    y_col = class_col,\n",
    "    target_size = (112, 112),\n",
    "    color_mode='rgb',\n",
    "    class_mode='other',\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-intelligence",
   "metadata": {},
   "source": [
    "## 3. Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-interaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "# 입력 데이터의 형태를 꼭 명시해야 합니다.\n",
    "model.add(Flatten(input_shape = (112, 112, 3))) # (112, 112, 3) -> (112 * 112 * 3)\n",
    "model.add(Dense(128, activation = 'relu')) # 128개의 출력을 가지는 Dense 층\n",
    "model.add(Dense(64, activation = 'relu')) # 64개의 출력을 가지는 Dense 층\n",
    "model.add(Dense(11, activation = 'sigmoid')) # 11개의 출력을 가지는 신경망\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "nonprofit-geometry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "349/349 [==============================] - 23s 67ms/step - loss: 0.5599 - acc: 0.3473 - val_loss: 0.3117 - val_acc: 0.5090\n",
      "Epoch 2/10\n",
      "349/349 [==============================] - 23s 65ms/step - loss: 0.3036 - acc: 0.4303 - val_loss: 0.3093 - val_acc: 0.4023\n",
      "Epoch 3/10\n",
      "349/349 [==============================] - 23s 66ms/step - loss: 0.2620 - acc: 0.4665 - val_loss: 0.2696 - val_acc: 0.4504\n",
      "Epoch 4/10\n",
      "349/349 [==============================] - 23s 66ms/step - loss: 0.2275 - acc: 0.5197 - val_loss: 0.2587 - val_acc: 0.5947\n",
      "Epoch 5/10\n",
      "349/349 [==============================] - 23s 67ms/step - loss: 0.2129 - acc: 0.5332 - val_loss: 0.2158 - val_acc: 0.5437\n",
      "Epoch 6/10\n",
      "349/349 [==============================] - 23s 66ms/step - loss: 0.1966 - acc: 0.5579 - val_loss: 0.2459 - val_acc: 0.5625\n",
      "Epoch 7/10\n",
      "349/349 [==============================] - 23s 67ms/step - loss: 0.1956 - acc: 0.5563 - val_loss: 0.2081 - val_acc: 0.5709\n",
      "Epoch 8/10\n",
      "349/349 [==============================] - 23s 67ms/step - loss: 0.1802 - acc: 0.5792 - val_loss: 0.2401 - val_acc: 0.5249\n",
      "Epoch 9/10\n",
      "349/349 [==============================] - 23s 66ms/step - loss: 0.1652 - acc: 0.5936 - val_loss: 0.2844 - val_acc: 0.5295\n",
      "Epoch 10/10\n",
      "349/349 [==============================] - 23s 66ms/step - loss: 0.1616 - acc: 0.6070 - val_loss: 0.2128 - val_acc: 0.5939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18a5f427fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "         steps_per_epoch=get_steps(len(train_df), batch_size),\n",
    "         validation_data = val_generator,\n",
    "         validation_steps=get_steps(len(val_df), batch_size),\n",
    "         epochs = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
