{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2acd43",
   "metadata": {},
   "source": [
    "## 14. FastText\n",
    "- 페이스북에서 개발, 메커니즘 자체는 Word2Vec의 확장\n",
    "- Word2Vec와 FastText와의 가장 큰 차이점\n",
    "    - Word2Vec는 단어를 쪼개질 수 없는 단위로 생각\n",
    "    - FastText는 하나의 단어 안에도 여러 단어들이 존재하는 것으로 간주\n",
    "        - 즉 내부 단어(subword)를 고려하여 학습\n",
    "        \n",
    "### 14.1 내부 단어(subword)의 학습\n",
    "- FastText에서는 각 단어는 글자 단위 n-gram의 구성으로 취급\n",
    "- n을 몇으로 결정하는지에 따라서 단어들이 얼마나 분리되는지 결정\n",
    "    - 시작과 끝을 의미하는 <, >를 도입\n",
    "    - n을 3으로 잡은 트라이그램(tri-gram)의 경우, <ap, app, ppl, ple, le> \n",
    "    - 내부 단어들을 벡터화한다는 의미는 저 단어들에 대해서 Word2Vec을 수행한다는 의미\n",
    "\n",
    "### 14.2 Out Of Vocabulary, OOV)에 대한 대응\n",
    "- 각 모든 단어에 n-gram에 대해 워드 임베딩이 되고, 데이터 셋만 충분하다면 내부 단어 (subword)를 통해 모르는 단어 (OOV)에 대해서도 다른 단어와의 유사도 계산 가능\n",
    "- 모르는 단어에 제대로 대처할 수 없는 Word2Vec, GloVe와는 다른 점\n",
    "\n",
    "### 14.3 Rare Word에 대한 대응\n",
    "- Word2Vec\n",
    "    - 등장빈도 수가 적은 단어(rare word)에 대해서는 임베딩의 정확도가 높지 않음\n",
    "    - 참고할 수 있는 경우의 수가 적다보니 정확하게 임베딩이 되지 않는 경우\n",
    "\n",
    "- FastText\n",
    "    - 단어가 희귀 단어라도, 그 단어의 n-gram이 다른 단어의 n-gram과 겹치는 경우라면, Word2Vec과 비교하여 비교적 높은 임베딩 벡터값을 얻음\n",
    "    - FastText가 노이즈가 많은 코퍼스에서 강점을 가짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f0ca6",
   "metadata": {},
   "source": [
    "### 예제 코드\n",
    "- https://wikidocs.net/22883"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c33b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "model = FastText(result, size=100, window=5, min_count=5, workers=4, sg=1)\n",
    "model.wv.most_similar(\"electrofishing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b3d808",
   "metadata": {},
   "source": [
    "### 14.4 한국어에서의 FastText\n",
    "- OOV를 해결하기 위한 시도 존재\n",
    "    - (1) 음절 단위\n",
    "        - <자연, 자연어, 연어처, 어처리, 처리>\n",
    "    - (2) 자모 단위\n",
    "        - ㅈ ㅏ _ ㅇ ㅕ ㄴ ㅇ ㅓ _ ㅊ ㅓ _ ㄹ ㅣ _\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
