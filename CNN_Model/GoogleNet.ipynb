{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Net (Inception V1 모델)\n",
    "- 구글의 체게디 등이 개발 , 2014 우승\n",
    "- Google Net 과 VGGNet은 동등한 시기에 나왔으나, VGGNet 이 좀 더 간편해서 VGG가 더 많이 유명해짐\n",
    "\n",
    "![googlenet](img/googlenet.png)\n",
    "\n",
    "### GoogleNet 배경\n",
    "- 이전까지 나온 아이디어는 깊고 넓을 수록 성능이 좋다\n",
    "- 학습시키는데 오래걸린다, 연산량이 많다 파라메터가 많다\n",
    "- 깊고 넓을 수록 좋은 모델일까????\n",
    "\n",
    "<hr><hr>\n",
    "\n",
    "### GoogleNet 아이디어\n",
    "- 주요 아이디어\n",
    "    - (1) 파라메터 수를 줄이자!\n",
    "        - 1x1 conv(width와 height는 줄지 않고 채널별로 묶음)\n",
    "        - Tensor factorization (행렬을 다른 행렬로 분해 했을떄 파라미터가 줄수있다)\n",
    "    - (2) 연산을 효율적으로 하려면 어떻게 해야할까?\n",
    "        - matrix 연산이 dense해야 한다.\n",
    "    - (3) 깊은 layer까지 정보를 전달 (gradient descent)\n",
    "        - auxilliary layer(auxiliary classifier) : 가중치를 쭉 갔으면 gradient descent가 발생하니까 중간에 끝내고, 이게 정답값이야 하고 딱 못박고 다음것부터 이제 다시 해당 정답값과 오차 계산해나감\n",
    "        - **즉 역전파에서 기울기 소실이 발생하는 것을 방지하기 위해 같은 문제를 여러 단계서 풀음**\n",
    "        - 기울기 소멸 문제 완화 장치로 4번째, 7번째 계층에 보조 분류기 추가 / 보조 분류기를 통해 그레디언트 정보 제공\n",
    "        - **학습때는 auxiliary classifier 사용, 추론시에는 사용하지 않고 마지막 classifier만 사용**\n",
    "\n",
    "    - (4) Overfitting이 덜되는 general 한 구조 \n",
    "        - 네트워크를 sparse 한 convolution 으로 진행\n",
    "    - ==> Inception 모듈의 등장\n",
    "    \n",
    "\n",
    "\n",
    "- **main 분류기가 있어서 쭉 가지만 좀 성능이 떨어지더라도 중간 분류기를 달음**\n",
    "### Inception 모듈\n",
    "![inception_module1](img/inception_module1.png)\n",
    "- 다양한 feature를 뽑기 위해 여러 conv 병렬 사용(local sparse structure conv)\n",
    "- 마지막엔 이를 concatenation 하는데 이 과정이 dense matrix 이다. \n",
    "- 1x1 conv / 3x3 conv / 5x5 conv / 3x3 maxpooling\n",
    "\n",
    "![inception_module2](img/inception_module2.png)\n",
    "- (a)보다 (b)가 더 성능을 잘낸다.\n",
    "- **(b) 는 1x1이 다 들어갔는데, 1x1이 들어갔을 때, 확실히 non-linear 특성을 증가시키면서, 채널들간의 linear combination 가능 ==> 1x1 dimension reduction **\n",
    "- 마지막 Dense 로 모아주고 다시 경우를 나누고 펼치고 다시 모으고 이런식\n",
    "- **1x1 컨볼루션 : 동일한 위치의 특징맵 값을 필터의 가중치와 선형 결합, 1x1 컨볼루션 필터의 개수를 조정하여 출력되는 특징지도의 개수를 조정**\n",
    "\n",
    "\n",
    "### Tensor Factorization\n",
    "- n x n 을 => 1xn, nx1 로 바꾸는것이 보다 효율적임\n",
    "\n",
    "![tensor_factorization](img/tensor_factorization.png)\n",
    "\n",
    "### Inception V2\n",
    "- Tensor Factorization 을 이용하여 연산량을 매우감소시킴\n",
    "- Inception V2와 V3 는 같이 나옴.\n",
    "- 아래는 원본과 A 모듈 사진 원본 -> A로 \n",
    "![inception_module_원본](img/inception_module_원본.PNG)\n",
    "![inception_module_a](img/inception_module_a.PNG)\n",
    "\n",
    "### Grid Reduction 방법\n",
    "- pooling과 conv 중 어느걸 먼저 해야될지 선택\n",
    "- Pooling을 먼저 할 시 Representational Bottle neck 현상 발생 - 해상도가 바로 줄고 정보 손실이 좀 있음\n",
    "- CNN을 먼저 할 시 Pooling 먼저 하는 것보단 연산량이 좀더 많다\n",
    "- 두개의 장단점이 있고 두개를 잘 조합해서 하자라고 함 (Grid Reduction 모듈)\n",
    "\n",
    "### Inception V3\n",
    "- Inception V2 + Grid Reduction 추가\n",
    "\n",
    "- Inception V2 를 Tensor Factorization 한번 더 한 것 (모듈 B)\n",
    "![inception_module_b](img/inception_module_b.PNG)\n",
    "\n",
    "- Inception V3 + Grid Reduction (모듈 C)\n",
    "- Representation Bootleneck을 줄이기 위해서 Filter bank가 expanded된 형태\n",
    "![inception_module_c](img/inception_module_c.PNG)\n",
    "\n",
    "- 최종 Inception V3\n",
    "![inception_v3](img/inception_v3.PNG)\n",
    "\n",
    "- 22개 층 모델이지만, AlexNet 모델에 비해 가중치 개수는 10% 증가\n",
    "\n",
    "### BottleNeck\n",
    "![bottleneck](img/bottleneck.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
