{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93cec8b3",
   "metadata": {},
   "source": [
    "\n",
    "## BERT (Bidirectional Encoder Representation from Transformers)\n",
    "- BERT는 다양한 자연어처리 분야에 적용되어 많은 성능 향상을 보이고 있으며, 대용량 코퍼스를 언어 모델(language model)로 학습한 모델이다. \n",
    "- **사전 학습 된 BERT 모델에 출력 층(output layer)을 추가한 후에 fine-tuning 하는 방법**으로 적용가능\n",
    "- BERT는 OOV (Out Of Vocabulary) 문제를 해결하기 위하여 BPE (Byte Pair Encoding)를 적용\n",
    "- BERT는 양방향성을 가진 트랜스포머(transformer)를 기반으로 하며, 각 블록(block)의 셀프 어텐션 매커니즘(self-attention mechanism)으로 문맥 전체를 확인하여 언어 모델을 학습\n",
    "- 문장 내에서 임의의 단어를 마스킹(masking)하고 이를 예측하는 masked language modeling (masked LM)을 학습\n",
    "- 주어진 두 문장이 연결된 문장인지 예측하는 다음 문장 예측(next sentence prediction)을 함께 학습\n",
    "\n",
    "\n",
    "## BERT 적용\n",
    "- BERT의 입력 형태소에 BPE를 적용하여 토큰화(tokenization)를 진행\n",
    "- BPE를 적용했을 때 형태소 단위를 구분하기 위해, 각 형태소의 마지막 토큰에는 “_”을 붙임\n",
    "- 모든 입력열의 첫 번째 토큰으로는 [CLS]가 주어지며, 분류 문제를 해결할 때 해당 토큰의 벡터를 이용\n",
    "- BERT를 언어 모델로 사전 학습 할 때는 구분자 [SEP]를 사용하여 두 개의 열(sequence)를 연결하여 하나의 입력으로 만듬\n",
    "\n",
    "## 데이터\n",
    "- NSMC(Naver Movie Data) (NSMC의 학습 데이터는 15만개, 평가 데이터는 5만개)\n",
    "- 다음&카카오 영화평 데이터 존재 (학습 109,066개, 검증 13,634개, 평가 13,634개\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f8041",
   "metadata": {},
   "source": [
    "\n",
    "## SKT KOBERT\n",
    "- SKT Brain의 KoBERT[6]는 기존 BERT 모델에 한국어 위치 데이터와 뉴스 2천만 문장을 추가 학습하여 한국에 데이터에 잘 대응할 수 있는 모델\n",
    "\n",
    "## BPE 토크나이저\n",
    "- 자소 단위 BPE 토크나이저\n",
    "- 한국어 모델에서의 입력은 대부분 형태소 단위나 음절 단위의 토큰을 사용하게 되는데 형태소 단위의 토큰은 형태소 분석기의 오류의 전파와 OOV(Out Of Vocabulary)의 문제점이 존재\n",
    "- 음절 단위 토큰은 입력 토큰의 의미를 구분하는데 어려움이 존재\n",
    "- EX) 입력 문장: 난 프랑스 영화가 이래서 좋다\n",
    "- EX) 결과 토큰: _난 _프랑스 _영화 가 _이래 서 _좋다 . ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3ceed",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "- https://yngie-c.github.io/nlp/2020/07/04/nlp_bert/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
