{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a60b77",
   "metadata": {},
   "source": [
    "# 11. Word2Vec\n",
    "- 적당하게 데이터를 나열해주면 Word2vec은 위치가 근접한 데이터를 유사도가 높은 벡터를 만들어준다는 점에서 착안된 아이디어\n",
    "- Word2Vec에서 입력은 모두 원-핫 벡터가 되어야 하며, 아래 그림은 중심 단어와 주변 단어를 어떻게 선택했을 때에 따라서 각각 어떤 원-핫 벡터가 되는지를 보여줌\n",
    "- Word2Vec는 입력층과 출력층 사이에 하나의 은닉층만이 존재\n",
    "- Word2Vec의 은닉층은 일반적인 은닉층과는 달리 활성화 함수가 존재하지 않으며 룩업 테이블이라는 연산을 담당하는 층으로 일반적인 은닉층과 구분하기 위해 투사층(projection layer)이라고 부름\n",
    "-  Word2Vec의 출력층에서는 소프트맥스 함수를 지난 단어 집합 크기의 벡터와 실제값인 원-핫 벡터와의 오차를 구하고 이로부터 임베딩 테이블에 있는 모든 단어에 대한 임베딩 벡터 값을 업데이트\n",
    "- 만약 단어 집합의 크기가 수만 이상에 달한다면 이 작업은 굉장히 무거운 작업이므로, Word2Vec은 꽤나 학습하기에 무거운 모델\n",
    "\n",
    "## 11.1 CBoW (Continuous Bag of Words)\n",
    "\n",
    "- Word2Vec에는 CBoW(Continuous Bag of Words)와 Skip-Gram 두 가지 방식\n",
    "- CBOW는 주변에 있는 단어들을 가지고, 중간에 있는 단어들을 예측하는 방법\n",
    "    - 예측 해야하는 단어 sat을 중심 단어(center word)라고 하고, 예측에 사용되는 단어들을 주변 단어(context word)\n",
    "    - 중심 단어를 예측하기 위해 앞, 뒤로 몇 개의 단어를 볼지를 결정 했다면 이 범위를 윈도우(window)라고 함\n",
    "\n",
    "![cbow](img/cbow.png)\n",
    "\n",
    "![cbow_model](img/cbow_model.png)\n",
    "\n",
    "## 11.2 Skip-gram\n",
    "- Skip-Gram은 중간에 있는 단어로 주변 단어들을 예측하는 방법\n",
    "- 중심 단어에 대해서 주변 단어를 예측하므로 투사층에서 벡터들의 평균을 구하는 과정은 없음\n",
    "- 전반적으로 Skip-gram이 CBOW보다 성능이 좋다고 알려짐\n",
    "![skipgram](img/skipgram.png)\n",
    "![skipgram_model](img/skipgram_model.png)\n",
    "\n",
    "## 11.3 NNLM vs CBOW\n",
    "- NNLM은 단어 간 유사도를 구할 수 있도록 워드 임베딩의 개념을 도입\n",
    "- NNLM의 느린 학습 속도와 정확도를 개선하여 탄생한 것이 Word2Vec\n",
    "- NNLM은 언어 모델이므로 다음 단어를 예측하지만, Word2Vec(CBOW)은 워드 임베딩 자체가 목적이므로 다음 단어가 아닌 중심 단어를 예측하며 학습\n",
    "- 중심 단어를 예측하게 하므로서 NNLM이 예측 단어의 이전 단어들만을 참고하였던 것과는 달리, Word2Vec은 예측 단어의 전, 후 단어들을 모두 참고\n",
    "\n",
    "![nnlm_vs_cbow](img/nnlm_vs_cbow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c83b22a",
   "metadata": {},
   "source": [
    "## 11.4 Word2Vec - 영어\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c353113",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Black\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "691cb1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x1ed2db3d2e0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "from lxml import etree\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# 데이터 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/GaoleMeng/RNN-and-FFNN-textClassification/master/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b68e163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 273424\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 전처리하기\n",
    "targetXML=open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
    "target_text = etree.parse(targetXML)\n",
    "\n",
    "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))\n",
    "\n",
    "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
    "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)\n",
    "\n",
    "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
    "sent_text = sent_tokenize(content_text)\n",
    "\n",
    "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "    normalized_text.append(tokens)\n",
    "\n",
    "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]\n",
    "print('총 샘플의 개수 : {}'.format(len(result)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b3c854",
   "metadata": {},
   "source": [
    "## 11.4.1 Gensim 패키지로 Word2vec 훈련\n",
    "- size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
    "- window = 컨텍스트 윈도우 크기\n",
    "- min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습하지 않는다.)\n",
    "- workers = 학습을 위한 프로세스 수\n",
    "- sg = 0은 CBOW, 1은 Skip-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018c6e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8443767428398132), ('guy', 0.8202828764915466), ('lady', 0.7593144774436951), ('boy', 0.7437211275100708), ('girl', 0.7327985167503357), ('gentleman', 0.707787275314331), ('soldier', 0.7002344727516174), ('kid', 0.6947757601737976), ('poet', 0.6676875352859497), ('son', 0.6554825901985168)]\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec 훈련시키기\n",
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)\n",
    "model_result = model.wv.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6a20e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8443767428398132), ('guy', 0.8202828764915466), ('lady', 0.7593144774436951), ('boy', 0.7437211275100708), ('girl', 0.7327985167503357), ('gentleman', 0.707787275314331), ('soldier', 0.7002344727516174), ('kid', 0.6947757601737976), ('poet', 0.6676875352859497), ('son', 0.6554825901985168)]\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec 모델 저장하고 로드하기\n",
    "from gensim.models import KeyedVectors\n",
    "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드\n",
    "model_result = loaded_model.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f2e8e",
   "metadata": {},
   "source": [
    "## 11.5. 한국어 Word2Vec 만들기 - NSML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e08a9948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "True\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Black\\AppData\\Local\\Temp/ipykernel_15532/1471407922.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...      1\n",
       "2   4655635                   폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고      1\n",
       "3   9251303   와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지      1\n",
       "4  10067386                         안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")\n",
    "train_data = pd.read_table('ratings.txt')\n",
    "print(len(train_data)) # 리뷰 개수 출력\n",
    "\n",
    "# 전처리\n",
    "print(train_data.isnull().values.any())\n",
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인\n",
    "\n",
    "# 정규 표현식을 통한 한글 외 문자 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "    \n",
    "# 데이터 상위 5개\n",
    "train_data[:5] # 상위 5개 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c01d4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 72\n",
      "리뷰의 평균 길이 : 10.716703668146726\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcbklEQVR4nO3dfbhWdZ3v8fdHVHRMBYS4CKxNyVXRTKLi05XNQT0haif1OmZyppGMkZnC0c5YE0yddCxPeHVGG5tywiSxMcnjQ3KUkRjCcZwS2SjJg3ncIR5hUFBAUScM/J4/1m+Pi+292YvFXvfD3p/Xda3rXuu7nr733sCXtdZv/X6KCMzMzMrYr9EJmJlZ63IRMTOz0lxEzMysNBcRMzMrzUXEzMxK27/RCdTb0KFDo62trdFpmJm1lOXLl78YEcO6xvtdEWlra6O9vb3RaZiZtRRJz9aK+3aWmZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZldbv3lhvZm0z7q8ZXzfr7DpnYmZWjK9EzMysNBcRMzMrrbIiIukgSY9K+pWk1ZL+OsVHS1oqqUPSTyQdmOID03JHWt+WO9bMFH9K0hm5+KQU65A0o6rvYmZmtVV5JbIDOC0ijgbGAZMknQRcC1wfEUcBW4GpafupwNYUvz5th6SxwIXAh4BJwPckDZA0APgucCYwFpictjUzszqprIhE5tW0eECaAjgNuDPF5wLnpvlz0jJp/emSlOLzImJHRDwDdAAnpKkjItZGxBvAvLStmZnVSaXPRNIVwwpgE7AI+A2wLSJ2pk3WAyPT/EjgOYC0/mXgiHy8yz7dxWvlMU1Su6T2zZs398I3MzMzqLiIRMSuiBgHjCK7cvhAlefbQx6zI2J8RIwfNuxtA3OZmVlJdWmdFRHbgCXAycAgSZ3vp4wCNqT5DcCRAGn94cBL+XiXfbqLm5lZnVTZOmuYpEFp/mDgY8CTZMXk/LTZFODeND8/LZPW/zwiIsUvTK23RgNjgEeBZcCY1NrrQLKH7/Or+j5mZvZ2Vb6xPgKYm1pR7QfcERH3SVoDzJP0DeBx4Oa0/c3AjyR1AFvIigIRsVrSHcAaYCcwPSJ2AUi6FFgIDADmRMTqCr+PmZl1UVkRiYgngGNqxNeSPR/pGv8t8MlujnUNcE2N+AJgwT4na2ZmpfiNdTMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxK88iGFfJIhWbW1/lKxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSKisiko6UtETSGkmrJV2e4ldJ2iBpRZrOyu0zU1KHpKcknZGLT0qxDkkzcvHRkpam+E8kHVjV9zEzs7er8kpkJ3BFRIwFTgKmSxqb1l0fEePStAAgrbsQ+BAwCfiepAGSBgDfBc4ExgKTc8e5Nh3rKGArMLXC72NmZl1UVkQiYmNEPJbmtwNPAiP3sMs5wLyI2BERzwAdwAlp6oiItRHxBjAPOEeSgNOAO9P+c4FzK/kyZmZWU12eiUhqA44BlqbQpZKekDRH0uAUGwk8l9ttfYp1Fz8C2BYRO7vEa51/mqR2Se2bN2/uja9kZmbUoYhIegdwF/CFiHgFuBF4HzAO2Aj8TdU5RMTsiBgfEeOHDRtW9enMzPqN/as8uKQDyArIbRFxN0BEvJBbfxNwX1rcAByZ231UitFN/CVgkKT909VIfnszM6uDKltnCbgZeDIirsvFR+Q2Ow9YlebnAxdKGihpNDAGeBRYBoxJLbEOJHv4Pj8iAlgCnJ/2nwLcW9X3MTOzt6vySuQjwB8DKyWtSLG/ImtdNQ4IYB3wpwARsVrSHcAaspZd0yNiF4CkS4GFwABgTkSsTsf7MjBP0jeAx8mKlpmZ1UllRSQiHgZUY9WCPexzDXBNjfiCWvtFxFqy1ltmZtYAfmPdzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9J6LCKSPinp0DT/VUl3Szq2+tTMzKzZFbkS+R8RsV3SKcB/Jnuh78Zq0zIzs1ZQpIjsSp9nA7Mj4n7Agz+ZmVmhN9Y3SPo+8DHgWkkD8bOUptA24/5u162bdXYdMzGz/qpIMbiArN+qMyJiGzAE+FKVSZmZWWvosYhExOvAJuCUFNoJPF1lUmZm1hqKtM66kqy33JkpdADwD1UmZWZmraHI7azzgE8ArwFExL8Bh1aZlJmZtYYiReSNNABUAEg6pNqUzMysVRQpInek1lmDJF0C/BNwU7VpmZlZK+ixiW9E/C9JHwNeAd4PfC0iFlWemZmZNb1CIxumouHCYWZmu+m2iEjaTnoO0nUVEBFxWGVZmZlZS+i2iESEW2CZmdkeFbqdlXrtPYXsyuThiHi80qzMzKwlFHnZ8GvAXOAIYChwi6SvVp2YmZk1vyJXIn8EHB0RvwWQNAtYAXyjwrzMzKwFFHlP5N+Ag3LLA4EN1aRjZmatpEgReRlYLekWST8EVgHbJN0g6YbudpJ0pKQlktZIWi3p8hQfImmRpKfT5+AUVzpmh6Qn8qMnSpqStn9a0pRc/DhJK9M+N0hS2R+EmZntvSK3s+5JU6cHCx57J3BFRDyWhtddLmkR8BlgcUTMkjQDmEHWweOZwJg0nUg2euKJkoYAVwLjyR7sL5c0PyK2pm0uAZYCC4BJwD8WzM/MzPZRkTfW55Y5cERsBDam+e2SngRGAucAE9Jmc8mK0pdT/NbUT9cjkgZJGpG2XRQRWwBSIZok6UHgsIh4JMVvBc7FRcTMrG6KtM76uKTHJW2R9Iqk7ZJe2ZuTSGoDjiG7YhieCgzA88DwND8SeC632/oU21N8fY14rfNPk9QuqX3z5s17k7qZme1BkWci3wamAEdExGERcejevK0u6R3AXcAXImK34pPvHbhKETE7IsZHxPhhw4ZVfTozs36jSBF5DliV/sHfK5IOICsgt0XE3Sn8QrpNRfrclOIbgCNzu49KsT3FR9WIm5lZnRQpIn8JLJA0U9JfdE497ZRaSt0MPBkR1+VWzSe7siF93puLX5RaaZ0EvJxuey0EJkoanFpyTQQWpnWvSDopneui3LHMzKwOirTOugZ4lexdkQP34tgfAf4YWClpRYr9FTCLbIySqcCzwAVp3QLgLKADeB24GCAitkj6OrAsbXd150N24PPALcDBZA/U/VDdzKyOihSRd0XE7+/tgSPiYbIef2s5vcb2AUzv5lhzgDk14u3AXudmZma9o8jtrAWSJlaeiZmZtZwiReRzwAOS/r1sE18zM+ubirxs6HFFzMyspqLjiQwm647kPzpijIiHqkrKzMxaQ49FRNKfAJeTvYexAjgJ+CVwWqWZmZlZ0yvyTORy4Hjg2Yg4laz7km1VJmVmZq2hSBH5bW5AqoER8Wvg/dWmZWZmraDIM5H1kgYBPwUWSdpK9pKgmZn1c0VaZ52XZq+StAQ4HHig0qzMzKwlFOkK/n2SBnYuAm3A71WZlJmZtYYiz0TuAnZJOgqYTdaj7o8rzcrMzFpCkSLyZkTsBM4DvhMRXwJGVJuWmZm1giJF5HeSJpN1235fih1QXUpmZtYqihSRi4GTgWsi4hlJo4EfVZuWmZm1giKts9YAl+WWnwGurTIpMzNrDUWuRMzMzGoq1AGj9a62Gfc3OgUzs17R7ZWIpB+lz8vrl46ZmbWSPd3OOk7Su4DPShosaUh+qleCZmbWvPZ0O+vvgcXAe4Hl7D5eeqS4mZn1Y91eiUTEDRHxQWBORLw3IkbnJhcQMzMr1MT3c5KOBj6aQg9FxBPVpmVmZq2gSAeMlwG3Ae9M022S/rzqxMzMrPkVaeL7J8CJEfEagKRryYbH/U6ViZmZWfMr8rKhgF255V3s/pC99k7SHEmbJK3Kxa6StEHSijSdlVs3U1KHpKcknZGLT0qxDkkzcvHRkpam+E8kHVjgu5iZWS8qUkR+CCxNBeAq4BHg5gL73QJMqhG/PiLGpWkBgKSxwIXAh9I+35M0QNIA4LvAmcBYYHLaFrKuV66PiKOArcDUAjmZmVkv6rGIRMR1ZJ0wbknTxRHx7QL7PZS2L+IcYF5E7Eh9c3UAJ6SpIyLWRsQbwDzgHEkCTgPuTPvPBc4teC4zM+slhbo9iYjHgMd66ZyXSroIaAeuiIitwEiyK5xO61MM4Lku8ROBI4BtaZyTrtubmVmd1LsDxhuB9wHjgI3A39TjpJKmSWqX1L558+Z6nNLMrF+oaxGJiBciYldEvAncRHa7CmAD2bC7nUalWHfxl4BBkvbvEu/uvLMjYnxEjB82bFjvfBkzM9tzEUkPt5f01skk5YfVPQ/obLk1H7hQ0sA06NUY4FFgGTAmtcQ6kOzh+/yICGAJcH7afwpwb2/laWZmxezxmUhE7JL0pqTDI+LlvTmwpNuBCcBQSeuBK4EJksaR9b21DvjTdJ7Vku4A1gA7gekRsSsd51JgITCArAuW1ekUXwbmSfoG8DjFWoyZmVkvKvJg/VVgpaRFwGudwYi4rPtdICIm1wh3+w99RFwDXFMjvgBYUCO+lrduh5mZWQMUKSJ3p8nMzGw3RTpgnCvpYODdEfFUHXIyM7MWUaQDxv8CrAAeSMvjJM2vOC8zM2sBRZr4XkX27GEbQESswANSmZkZxYrI72q0zHqzimTMzKy1FHmwvlrSfwMGSBoDXAb8otq0zMysFRQpIn8OfAXYAdxO9s7G16tMynbXNuP+RqdgZlZTkdZZrwNfSYNRRURsrz4tMzNrBUVaZx0vaSXwBNlLh7+SdFz1qZmZWbMrcjvrZuDzEfEvAJJOIRuo6sNVJmb11d0ts3Wzzq5zJmbWSoq0ztrVWUAAIuJhsv6tzMysn+v2SkTSsWn2nyV9n+yhegCfAh6sPjUzM2t2e7qd1XXAqCtz81FBLmZm1mK6LSIRcWo9EzEzs9bT44N1SYOAi4C2/PY9dQVvZmZ9X5HWWQuAR4CVuLsTMzPLKVJEDoqIv6g8EzMzazlFmvj+SNIlkkZIGtI5VZ6ZmZk1vSJXIm8A3yLrP6uzVVbg7uDNzPq9IkXkCuCoiHix6mTMzKy1FLmd1QG8XnUiZmbWeopcibwGrJC0hKw7eMBNfM3MrFgR+WmazMzMdlNkPJG59UjEzMxaT5E31p+hRl9ZEeHWWWZm/VyRB+vjgePT9FHgBuAfetpJ0hxJmyStysWGSFok6en0OTjFJekGSR2Snsj1IIykKWn7pyVNycWPk7Qy7XODJBX/2mZm1ht6LCIR8VJu2hAR3waKjFR0CzCpS2wGsDgixgCL0zLAmcCYNE0DboSs6JD1HnwicAJwZWfhSdtcktuv67nMzKxiRW5nHZtb3I/syqTIs5SHJLV1CZ8DTEjzc8nGJflyit8aEQE8ImmQpBFp20URsSXlsgiYJOlB4LCIeCTFbwXOBf6xp7zMzKz3FGmdlR9XZCewDrig5PmGR8TGNP88MDzNjwSey223PsX2FF9fI16TpGlkVzi8+93vLpm6mZl1VeSKopJxRSIiJNVlcKuImA3MBhg/frwH1DIz6yVFbmcNBP4rbx9P5OoS53tB0oiI2JhuV21K8Q3AkbntRqXYBt66/dUZfzDFR9XY3szM6qjI7ax7gZeB5eTeWC9pPjAFmJU+783FL5U0j+wh+sup0CwE/mfuYfpEYGZEbJH0iqSTgKVkg2Z9Zx9z61PaZtxfM75uVpE2EWZmxRQpIqMiYq9bPkm6newqYqik9WStrGYBd0iaCjzLW89WFgBn8VY/XRcDpGLxdWBZ2u7qzofswOfJWoAdTPZA3Q/VzczqrEgR+YWkP4iIlXtz4IiY3M2q02tsG8D0bo4zB5hTI94O/P7e5GRmZr2rSBE5BfhMenN9ByCyf/c/XGlmZmbW9IoUkTMrz8LMzFpSkSa+z9YjETMzaz1FrkSsB921hDIz6+tcRPoZFzwz601FevE1MzOryUXEzMxKcxExM7PSXETMzKw0P1jfC34obWa2O1+JmJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqX5ZUMrpbsXL9fNOrvOmZhZI/lKxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKa0gRkbRO0kpJKyS1p9gQSYskPZ0+B6e4JN0gqUPSE5KOzR1nStr+aUlTGvFdzMz6s0ZeiZwaEeMiYnxangEsjogxwOK0DHAmMCZN04AbISs6wJXAicAJwJWdhcfMzOqjmW5nnQPMTfNzgXNz8Vsj8wgwSNII4AxgUURsiYitwCJgUp1zNjPr1xpVRAL4maTlkqal2PCI2JjmnweGp/mRwHO5fdenWHfxt5E0TVK7pPbNmzf31ncwM+v3GvXG+ikRsUHSO4FFkn6dXxkRISl662QRMRuYDTB+/PheO66ZWX/XkCISERvS5yZJ95A903hB0oiI2JhuV21Km28AjsztPirFNgATusQfrDj1fsfjypvZntT9dpakQyQd2jkPTARWAfOBzhZWU4B70/x84KLUSusk4OV022shMFHS4PRAfWKKmZlZnTTiSmQ4cI+kzvP/OCIekLQMuEPSVOBZ4IK0/QLgLKADeB24GCAitkj6OrAsbXd1RGyp39cwM7O6F5GIWAscXSP+EnB6jXgA07s51hxgTm/naGZmxTRTE18zM2sxLiJmZlaaB6WyuvAgVmZ9k69EzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0t86ypuTWXGatwVciZmZWmouImZmV5iJiZmal+ZmI9SqPP2LWv7iIWJ+2p6Lmh/Rm+863s8zMrDQXETMzK823s8y68DsqZsW5iFhD9YUH8Y0qOi521gxcRMyahIuCtSIXEWspfeHKxawvcREx6yfc3Nmq4CJi/Zavasz2nYuIWUGNKjoudtbMXETMKuKiY/2Bi4iZdcstxqwnLV9EJE0C/hYYAPwgImY1OCWzluOrFyurpYuIpAHAd4GPAeuBZZLmR8SaxmZm1rf5CsU6tXQRAU4AOiJiLYCkecA5gIuIWQNUfUXjItV8Wr2IjASeyy2vB07supGkacC0tPiqpKdKnm8o8GLJfevJefa+Vsm1T+epayvIpGd9+me6F95TK9jqRaSQiJgNzN7X40hqj4jxvZBSpZxn72uVXJ1n72uVXBuVZ6t3Bb8BODK3PCrFzMysDlq9iCwDxkgaLelA4EJgfoNzMjPrN1r6dlZE7JR0KbCQrInvnIhYXeEp9/mWWJ04z97XKrk6z97XKrk2JE9FRCPOa2ZmfUCr384yM7MGchExM7PSXEQKkDRJ0lOSOiTNaHQ+eZLmSNokaVUuNkTSIklPp8/Bjcwx5XSkpCWS1khaLenyZsxV0kGSHpX0q5TnX6f4aElL05+Bn6SGHA0naYCkxyXdl5abNc91klZKWiGpPcWa6nefchok6U5Jv5b0pKSTmy1PSe9PP8fO6RVJX2hUni4iPch1rXImMBaYLGlsY7PazS3ApC6xGcDiiBgDLE7LjbYTuCIixgInAdPTz7HZct0BnBYRRwPjgEmSTgKuBa6PiKOArcDUxqW4m8uBJ3PLzZonwKkRMS73LkOz/e4h64fvgYj4AHA02c+2qfKMiKfSz3EccBzwOnAPjcozIjztYQJOBhbmlmcCMxudV5cc24BVueWngBFpfgTwVKNzrJHzvWR9njVtrsDvAY+R9YLwIrB/rT8TDcxvFNk/FqcB9wFqxjxTLuuAoV1iTfW7Bw4HniE1OGrWPLvkNhH410bm6SuRntXqWmVkg3IpanhEbEzzzwPDG5lMV5LagGOApTRhrukW0QpgE7AI+A2wLSJ2pk2a5c/At4G/BN5My0fQnHkCBPAzSctTN0TQfL/70cBm4IfpFuEPJB1C8+WZdyFwe5pvSJ4uIn1cZP8taZp23JLeAdwFfCEiXsmva5ZcI2JXZLcKRpF18vmBxmb0dpI+DmyKiOWNzqWgUyLiWLLbwtMl/WF+ZZP87vcHjgVujIhjgNfockuoSfIEID3v+gTwv7uuq2eeLiI9a8WuVV6QNAIgfW5qcD4ASDqArIDcFhF3p3BT5goQEduAJWS3hQZJ6nw5txn+DHwE+ISkdcA8sltaf0vz5QlARGxIn5vI7t+fQPP97tcD6yNiaVq+k6yoNFuenc4EHouIF9JyQ/J0EelZK3atMh+YkuankD1/aChJAm4GnoyI63KrmipXScMkDUrzB5M9t3mSrJicnzZreJ4RMTMiRkVEG9mfyZ9HxB/RZHkCSDpE0qGd82T38VfRZL/7iHgeeE7S+1PodLJhJZoqz5zJvHUrCxqVZ6MfDLXCBJwF/F+ye+NfaXQ+XXK7HdgI/I7sf1JTye6NLwaeBv4JGNIEeZ5Cdnn9BLAiTWc1W67Ah4HHU56rgK+l+HuBR4EOstsHAxv9M83lPAG4r1nzTDn9Kk2rO/8ONdvvPuU0DmhPv/+fAoObNM9DgJeAw3OxhuTpbk/MzKw0384yM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRKzPkvRqBcccJ+ms3PJVkr64D8f7ZOotdknvZFg6j3WShjYyB2tNLiJme2cc2fstvWUqcElEnNqLxzSrGxcR6xckfUnSMklP5MYIaUtXATelsUN+lt5SR9LxadsVkr4laVXqseBq4FMp/ql0+LGSHpS0VtJl3Zx/chpPY5Wka1Psa2QvYd4s6Vtdth8h6aF0nlWSPpriN0pqV26skxRfJ+mbneN1SDpW0kJJv5H0Z2mbCemY9ysbH+fvJb3t3wBJn1Y2psoKSd9PHVIOkHRLymWlpP++j78S6ysa/ealJ09VTcCr6XMiMJusq/T9yLpN/0OyLvR3AuPSdncAn07zq4CT0/wsUlf7wGeAv8ud4yrgF8BAYCjZW8QHdMnjXcD/A4aRdfL3c+DctO5BYHyN3K/grTe7BwCHpvkhudiDwIfT8jrgc2n+erI3rg9N53whxScAvyV7g3wAWQ/F5+f2Hwp8EPg/nd8B+B5wEdm4FYty+Q1q9O/XU3NMvhKx/mBimh4nGx/kA8CYtO6ZiFiR5pcDbanvrEMj4pcp/uMejn9/ROyIiBfJOr3r2gX38cCDEbE5sm7abyMrYnuyDLhY0lXAH0TE9hS/QNJj6bt8iGygtE6dfbqtBJZGxPaI2Azs6OwPDHg0ItZGxC6yLnNO6XLe08kKxrLUHf7pZEVnLfBeSd+RNAl4BTOy/xWZ9XUCvhkR398tmI1rsiMX2gUcXOL4XY+xz3+vIuKh1F362cAtkq4D/gX4InB8RGyVdAtwUI083uyS05u5nLr2c9R1WcDciJjZNSdJRwNnAH8GXAB8dm+/l/U9vhKx/mAh8Nk0lgmSRkp6Z3cbR9YF/HZJJ6bQhbnV28luE+2NR4H/JGmosuGWJwP/vKcdJL2H7DbUTcAPyLokP4xsjIuXJQ0n6wp8b52QeqTeD/gU8HCX9YuB8zt/PsrG7X5Parm1X0TcBXw15WPmKxHr+yLiZ5I+CPwy65GeV4FPk101dGcqcJOkN8n+wX85xZcAM9Ktnm8WPP9GSTPSviK7/dVTN90TgC9J+l3K96KIeEbS48CvyUbb/Nci5+9iGfB3wFEpn3u65LpG0lfJRiHcj6x36OnAv5ON+Nf5H8+3XalY/+RefM1qkPSOiHg1zc8gG7v68gantU8kTQC+GBEfb3Aq1of4SsSstrMlzST7O/IsWassM+vCVyJmZlaaH6ybmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWn/Hx/QtCRb9/GjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## \n",
    "# 불용어 정의\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "# 형태소 분석기 OKT를 사용한 토큰화 작업 (다소 시간 소요)\n",
    "okt = Okt()\n",
    "tokenized_data = []\n",
    "for sentence in train_data['document']:\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(temp_X)\n",
    "    \n",
    "# 리뷰 길이 분포 확인\n",
    "print('리뷰의 최대 길이 :',max(len(l) for l in tokenized_data))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n",
    "plt.hist([len(s) for s in tokenized_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d4279bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16477, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(sentences = tokenized_data, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)\n",
    "\n",
    "# 완성된 임베딩 매트릭스의 크기 확인\n",
    "model.wv.vectors.shape\n",
    "print(model.wv.most_similar(\"최민식\"))\n",
    "print(model.wv.most_similar(\"히어로\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96cef0",
   "metadata": {},
   "source": [
    "## 11.6 한국어 Word2Vec 만들기 - 위키피디아\n",
    "- https://wikidocs.net/50739\n",
    "\n",
    "## 11.7 사전 훈련된 Word2Vec 임베딩(Pre-trained Word2Vec embedding) 소개\n",
    "- 구글이 제공하는 사전 훈련된(미리 학습되어져 있는) Word2Vec 모델\n",
    "    - https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "- 미리 학습된 Word2Vec 모델은 박규병님의 깃허브 주소\n",
    "    - https://drive.google.com/file/d/0B0ZXk88koS2KbDhXdWg1Q2RydlU/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db96c96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
