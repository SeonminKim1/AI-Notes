{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 Augmentation\n",
    "- 데이터가 적은 이미지에서 최대한 많은 정보를 뽑아내서 학습하는 기법\n",
    "- 이미지를 사용할 때마다 임의로 변형을 가하여 더 많은 이미지를 학습하는 것과 같은 효과를 냄\n",
    "- **과적합(overfitting) 방지**\n",
    "- ImageDataGenerator 클래스\n",
    "    - 학습 도중에 이미지에 임의 변형 및 정규화 적용\n",
    "    - generator 생성\n",
    "        - 변형된 이미지를 배치 단위로 불러옴\n",
    "        - flow(data, labels)\n",
    "        - flow_from_directory(directory) 두 가지 함수를 사용\n",
    "    - fir_generator, evaluate_generator 함수를 이용하여 generator로 이미지를 불러와서 모델을 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순 이미지 파일 증식\n",
    "- image file Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 112, 112, 3)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=40, #이미지 회전 범위 (degrees)\n",
    "                            width_shift_range=0.2, # 수평, 수직 랜덤 평행이동\n",
    "                            height_shift_range=0.2,\n",
    "                            rescale=1./255, # 입력값을 모델을 효과적으로 학습시키기에 너무 높은 값 255로 나눔\n",
    "                            shear_range = 0.2, #임의 전단 변환 (shearing transformation) 범위\n",
    "                            zoom_range = 0.2, #임의 확대/축소 범위\n",
    "                            horizontal_flip=True, # True로 설정할 경우, 50% 확률로 이미지를 수평으로 뒤집음. \n",
    "                             fill_mode='nearest' #이미지를 회전, 이동하거나 축소할 때 생기는 공간을 채우는 방식\n",
    "                            )\n",
    "\n",
    "# image 읽어오기\n",
    "pil_img = Image.open('data/cat/cat1.jpg')\n",
    "np_img = np.array(pil_img.convert('RGB'))\n",
    "np_img = np_img[np.newaxis, :]\n",
    "print(np_img.shape)\n",
    "\n",
    "# case 1 - datagen.flow() 함수\n",
    "i=0;\n",
    "for batch in datagen.flow(np_img, batch_size=1,\n",
    "                          save_to_dir='data', save_prefix='aug_cat', save_format='jpg'):\n",
    "    i+=1\n",
    "    if i>20:\n",
    "        print('20장 생성완료')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해당 폴더에 있는 이미지들 Augmentation\n",
    "- folder file aumentation\n",
    "- flow_from_directory() : 해당 폴더에 있는 이미지갯수와 라벨링 갯수를 알려줌\n",
    "    - Found 7 images belonging to 4 classes.\n",
    "- flow_from_directory는 이미지를 불러올 때 폴더명에 맞춰 자동으로 labeling을 해줌\n",
    "    - cat, cifar, dog 폴더 순이면 => 0, 1 ,2\n",
    "    - **img, label = iter.next() 를 통해서 일정한 배치만큼 받아옴**\n",
    "- 자동으로 \n",
    "\n",
    "- 폴더 형태\n",
    "    - cat\n",
    "        - cat1.jpg\n",
    "    - dog\n",
    "        - dog1.jpg\n",
    "    - cifar\n",
    "    - girin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 images belonging to 4 classes.\n",
      "한번에 뽑는 이미지 갯수(batch_size) 3\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 3\n",
    "iterations = 5\n",
    "image_width, image_height, channel = (112,112,3)\n",
    "path = 'data'\n",
    "\n",
    "datagen = ImageDataGenerator(rotation_range=40, #이미지 회전 범위 (degrees)\n",
    "                            width_shift_range=0.2, # 수평, 수직 랜덤 평행이동\n",
    "                            height_shift_range=0.2,\n",
    "                            rescale=1./255, # 입력값을 모델을 효과적으로 학습시키기에 너무 높은 값 255로 나눔\n",
    "                            shear_range = 0.2, #임의 전단 변환 (shearing transformation) 범위\n",
    "                            zoom_range = 0.2, #임의 확대/축소 범위\n",
    "                            horizontal_flip=True, # True로 설정할 경우, 50% 확률로 이미지를 수평으로 뒤집음. \n",
    "                            fill_mode='nearest' #이미지를 회전, 이동하거나 축소할 때 생기는 공간을 채우는 방식\n",
    "                            )\n",
    "\n",
    "obj = datagen.flow_from_directory(\n",
    "    path,\n",
    "    target_size = (image_width, image_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary')\n",
    "\n",
    "all_images = None\n",
    "print('한번에 뽑는 이미지 갯수(batch_size)', batch_size)\n",
    "\n",
    "# 어떤 모양으로 뽑히는지 시각화\n",
    "visualization(obj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPENCV 이용한 Data Generator 이미지 시각화 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(obj):\n",
    "    for i in range(iterations):\n",
    "        img, label = obj.next() # obj는 설정된 경로에서 batch_size에 맞춰 이미지를 불러옴\n",
    "        # label - cat : 0 / cifar : 1 / dog : 2\n",
    "\n",
    "        # 옆으로 붙이기\n",
    "        w_images=None\n",
    "        for idx, i_img in enumerate(img):\n",
    "            i_img = cv2.cvtColor(i_img, cv2.COLOR_RGB2BGR)  # keras는 RGB, openCV는 BGR이라 변경함\n",
    "            if idx==0:\n",
    "                w_images = i_img\n",
    "            else:\n",
    "                w_images = np.concatenate((w_images, i_img),axis=1)\n",
    "\n",
    "        # 부족한 갯수만큼 빈공간으로 채워주기\n",
    "        for i in range(batch_size-len(label)):\n",
    "            w_images=np.concatenate((w_images, \n",
    "                                     np.empty( shape =(image_width,image_height, channel))\n",
    "                                    ),axis=1)    \n",
    "        # 아래로 붙이기\n",
    "        if i==0:\n",
    "            all_images = w_images\n",
    "        else:\n",
    "            all_images = np.concatenate((all_images, w_images),axis=0)\n",
    "    cv2.imshow('result', all_images)\n",
    "    cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## history 시각화 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history 시각화 모듈\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualization_training(hist):\n",
    "    fig, loss_ax = plt.subplots()\n",
    "    acc_ax = loss_ax.twinx()\n",
    "    loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "    acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "    acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "    loss_ax.set_xlabel('epoch')\n",
    "    loss_ax.set_ylabel('loss')\n",
    "    acc_ax.set_ylabel('accuray')\n",
    "\n",
    "    loss_ax.legend(loc='upper left')\n",
    "    acc_ax.legend(loc='lower left')\n",
    "#     print(hist.history['loss'])\n",
    "#     print(hist.history['accuracy'])\n",
    "#     print(hist.history['val_loss'])\n",
    "#     print(hist.history['val_accuracy'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 10) (10000, 32, 32, 3) (10000, 10)\n",
      "(50000, 32, 32, 3) (50000, 10) (10000, 32, 32, 3) (10000, 10)\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_43 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,773,194\n",
      "Trainable params: 2,773,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "1094/1094 [==============================] - 519s 474ms/step - loss: 1.8290 - accuracy: 0.3185 - val_loss: 1.9489 - val_accuracy: 0.2968\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 22s 70ms/step - loss: 2.7152 - accuracy: 0.1003\n",
      "[2.715240955352783, 0.10029999911785126]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, \\\n",
    "    MaxPooling2D, Activation, Dense, Add, GlobalAveragePooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10) # 조기종료 콜백함수\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "dropout_rate = 0.5\n",
    "image_width, image_height, image_channel = (32,32,3)\n",
    "\n",
    "# 기본 Cifar Image load\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# one hot encode target values\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "# convert from integers to floats\n",
    "x_train = x_train.astype('float32')/ 255.0\n",
    "x_test = x_test.astype('float32')/ 255.0\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.3\n",
    ")\n",
    "\n",
    "# 특성별 정규화에 필요한 수치를 계산합니다\n",
    "# 샘플 데이터 배열 기반 데이터 의존적인 변형에 관련된 내적 데이터 통계를 계산\n",
    "# featurewise_center, featurewise_std_normalization, zca_whitening이 참일때만 필요\n",
    "datagen.fit(x_train)\n",
    "\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size=batch_size, subset='training')\n",
    "valid_generator = datagen.flow(x_train, y_train, batch_size=batch_size, subset='validation')\n",
    "\n",
    "# 모델 생성\n",
    "# block 1 - CCM\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(image_width, image_height, image_channel), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_rate))  \n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_rate))  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# block 2 - CM\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_rate))  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# block 3 - CM\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(dropout_rate))  \n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# block 4 - FF\n",
    "# classification layer\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 실시간 데이터 증강을 사용해 배치에 대해서 모델을 학습\n",
    "hist = model.fit_generator(train_generator,\n",
    "                           epochs=epochs,\n",
    "                           steps_per_epoch = len(train_generator), # len(x_train) // batch_size\n",
    "                           validation_data = valid_generator,\n",
    "                           callbacks=[early_stopping])\n",
    "\n",
    "visualization_training(hist)\n",
    "\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 20s 65ms/step - loss: 2.6610 - accuracy: 0.1866\n",
      "[2.6610171794891357, 0.186599999666214]\n"
     ]
    }
   ],
   "source": [
    "hist.history\n",
    "result = model.evaluate(x_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 총요약 !!\n",
    "\n",
    "#### 1. from tensorflow.keras.preprocessing.image import ImageDataGenerator 라이브러리 참조\n",
    "#### 2. datagen = ImageDataGenerator 객체 생성 \n",
    "- 어떠한 형태의 변형 augmentation에 대한 정보 가지고 있음\n",
    "- rotation_range=40, width_shift_range=0.2 등\n",
    "    \n",
    "#### 3. datagen.flow() / datagen.flow_from_directory() 사용\n",
    "- datagen.flow를 통해 생성된 이미지 배치 단위로 생성 및 저장\n",
    "- datagen.flow를 통한 학습에 대한 flow 생성 (train, valid 분리 등)\n",
    "- datagen.flow_from_directory()를 통한 이미지 배치 단위로 로드 \n",
    "- train_genertor = datagen.flow_from_directory() 폴더에서 읽어와서 생성 가능\n",
    "- valid_genertor = datagen.flow_from_directory() 폴더에서 읽어와서 생성 가능\n",
    "\n",
    "#### 4. fit_generator\n",
    "- model.fit_generator(train_generator, epochs, steps_per_epoch = len(train_generator) or len(x_train) // batch_size\n",
    "- validation_data = valid_generator, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고문헌\n",
    "- https://keras.io/ko/preprocessing/image/ // keras 공식 document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
